HF_TOKEN=
llm_model=meta-llama/Meta-Llama-3.1-8B-Instruct
llm_assistant_token="<|start_header_id|>assistant<|end_header_id|>\n\n"
embedding_model=jina-embeddings-v2-base-zh
embedding_provider=jina
trust_remote_code=True
force_cpu=False
vector_store_initial_load=True

provenance_method=rerank
provenance_similarity_llm=sentence-transformers/distiluse-base-multilingual-cased-v2
provenance_include_query=False
provenance_llm_prompt="指示：你是一位來源審計員，需要準確地確定使用者問題的答案有多少是基於給定的輸入文件，並知道不僅僅是使用了那一份文件。文件可能會被完整引用、部分引用，甚至被翻譯。你需要給出一個分數，表示來源文件在創建使用者問題答案時的使用程度。這個分數必須是：0 = 完全未使用來源文件，1 = 幾乎未使用，2 = 中等程度使用，3 = 大部分使用，4 = 幾乎全部使用，5 = 完整引用了文件內容到答案中。你只能回答0到5的分數，不能解釋，也不能添加除分數之外的文字。

使用者的問題是：

{query}

給出的答案是：

{answer}

你需要評分的來源文件如下：

{context}"

data_directory='rag/data'
file_types="pdf,json,docx,pptx,xslx,csv,xml,md"
json_schema="."
json_text_content=False
xml_xpath="//"

vector_store=chroma
persist_directory='rag/chroma'
vector_store_sparse_uri=bm25_db.pickle
vector_store_collection=ragmeup_documents
vector_store_k=20
document_chunks_pickle=rag_chunks.pickle
rerank=True
rerank_k=8
rerank_model=flashrank

temperature=0.2
repetition_penalty=1.1
max_new_tokens=1000

rag_instruction="指示：你是一位專業藥劑師，能夠快速且簡潔地回答有關相關內容的一般問題。以下是從資料庫中檢索到的幾個來自圖書館的文件，你可以使用這些文件來回答使用者的問題。務必清楚說明你的回答理由，並且總是提及你的來源，也就是你用來整理答案的文件。

{context}"

rag_question_initial="你需要回答的初始問題是：

{question}"

rag_question_followup="你需要回答的後續問題是：

{question}"

rag_fetch_new_instruction="指示：你是一位專業藥劑師，資料庫中包含與使用者問題相關的文件。使用者會根據這些文件提問，並可能提出需要你從資料庫中檢索新文件的問題，或者是基於先前獲得的文件進行後續提問。你需要判斷是否應該根據使用者的問題檢索新文件，或判斷這是否是基於先前文件的後續問題，但你無法看到使用者可能正在查看的實際文件。\n是否應該根據這個使用者的問題從資料庫中檢索新文件？請回yes或no。"

rag_fetch_new_question="使用者的問題如下：\"{question}\"\n"

use_rewrite_loop=False
rewrite_query_instruction="你需要根據從文件資料庫檢索到的文件來回答使用者的問題。你的任務是判斷這些文件是否包含使用者問題的答案。你只能回答「yes」或「no」。目前從資料庫檢索到的文件如下：

{context}"
rewrite_query_question="使用者的問題是:

{question}"
rewrite_query_prompt="你收到了一個使用者問題，應透過使用基於距離的相似性度量從文件庫中查找文件來回答該問題。然而，從文件庫中檢索到的文件與問題無關。請將以下問題重新改寫成能夠提高從資料庫中找到相關文件的可能性。你只能回答精確的改寫內容。原始問題是：{question}"

use_re2=False
re2_prompt="再讀一次問題: "

splitter='RecursiveCharacterTextSplitter'
chunk_size=512
chunk_overlap=80
breakpoint_threshold_type=percentile
breakpoint_threshold_amount=None
number_of_chunks=None

GOOGLE_API_KEY=your_key
JINA_API_KEY=your_key

use_openai=False
openai_model_name='gpt-4o-mini'
use_gemini=True
gemini_model_name='gemini-pro'
use_azure=False
use_ollama=False
ollama_model='llama3.1'

ragas_sample_size=200
ragas_qa_pairs=10
ragas_timeout=300
ragas_max_workers=1
ragas_question_instruction="You direct another LLM with questions. Write a question we can ask to an LLM that it will be able to answer based on these existing documents. Make sure the question can be accurately answered using the documents' contents and never ever reply with anything else but the question we need to supply to the LLM:

{context}"
ragas_question_query="Generate a question to that can be answered given the input documents, nothing else but the question and no explanation."
ragas_answer_instruction="You are a digital librarian and need to answer questions based on input documents. Here are the documents you are forced to base your answer on:

{context}"
ragas_answer_query="Answer the following question, never give any explanation or other output than the generated article itself:

{question}"